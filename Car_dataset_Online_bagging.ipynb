{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import csv\n",
    "from collections import Counter\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data \n",
    "#while running please change the path of the file \n",
    "car_data = pd.read_csv(\"F:/Semester 2/Machine Learning/Assignment/car.csv\",header = None,names = ['buying','maint','doors','persons','lug_boot','safety','class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vhigh' 'high' 'med' 'low'] \t 4\n",
      "['vhigh' 'high' 'med' 'low'] \t 4\n",
      "['2' '3' '4' '5more'] \t 4\n",
      "['2' '4' 'more'] \t 3\n",
      "['small' 'med' 'big'] \t 3\n",
      "['low' 'med' 'high'] \t 3\n",
      "['unacc' 'acc' 'vgood' 'good'] \t 4\n"
     ]
    }
   ],
   "source": [
    "#as all the columns are categorical, checking for unique values of each column\n",
    "for i in car_data.columns:\n",
    "    print(car_data[i].unique(),\"\\t\",car_data[i].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online bagging for Car Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "Precision is  0.6543654365436543\n",
      "Recall is  0.6543654365436543\n",
      "F1 score is  0.6543654365436543\n",
      "Accuracy is  0.6543654365436543\n",
      "time taken for online bagging 13.04143476486206\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global train_data\n",
    "global train_class\n",
    "global test_data\n",
    "global test_class\n",
    "global models\n",
    "global kArr\n",
    "\n",
    "#creating functions for precision, f1 score, recall and accuracy\n",
    "def f1score(y_true,y_pred):\n",
    "    f1=f1_score(y_true, y_pred, average= 'micro')\n",
    "    return f1\n",
    "def precision(y_true,y_pred):\n",
    "    pre=precision_score(y_true, y_pred, average='micro')\n",
    "    return pre\n",
    "def recall(y_true,y_pred):\n",
    "    recall=recall_score(y_true, y_pred, average='micro')\n",
    "    return recall\n",
    "def accuracy(y_true,y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "#Loading arriving data or online data\n",
    "def LoadData1(path):\n",
    "    global train_data\n",
    "    global train_class\n",
    "    global test_data\n",
    "    global test_class\n",
    "    #data encoding\n",
    "    data = []\n",
    "    with open(path) as csvfile:\n",
    "        data1 = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        for each in data1:\n",
    "            X = []\n",
    "            for x in each:\n",
    "                \n",
    "                #Applying hot encoding directly to the data coming in \n",
    "                if (x == \"vhigh\" or x == \"5more\" or x == \"more\"):\n",
    "                    x=3\n",
    "                elif (x == \"high\" or x == \"big\" or x == \"4\"):\n",
    "                    x=2\n",
    "                elif (x == \"med\" or x == \"3\"):\n",
    "                    x=1\n",
    "                elif (x == \"low\" or x == \"small\" or x == \"2\"):\n",
    "                    x=0\n",
    "                X.append(x)\n",
    "                Y = X\n",
    "                \n",
    "            #creating copies of the training data\n",
    "            if (Y[-1] == \"acc\"):\n",
    "                for i in range(3): \n",
    "                    data.append(Y)\n",
    "            elif (Y[-1] == \"good\"):\n",
    "                for i in range(10):\n",
    "                    data.append(Y)\n",
    "            elif (Y[-1] == \"vgood\"):\n",
    "                for i in range(10):\n",
    "                    data.append(Y)\n",
    "            else:\n",
    "                data.append(Y)\n",
    "        #splitting data into training and test set       \n",
    "    shuffle(data)\n",
    "    size = int(len(data) * 0.7)\n",
    "    train_data = data[0:size]\n",
    "    test_data = data[size:len(data)]\n",
    "    train_class = np.array(train_data)[:, len(train_data[0]) - 1]\n",
    "    train_data = np.array(train_data)[:, range(0, len(train_data[0]) - 1)]\n",
    "    test_class = np.array(test_data)[:, len(test_data[0]) - 1]\n",
    "    test_data = np.array(test_data)[:, range(0, len(test_data[0]) - 1)]\n",
    "    train_data = [[int(j) for j in i] for i in train_data]\n",
    "    test_data = [[int(j) for j in i] for i in test_data]\n",
    "    \n",
    "def addModels():\n",
    "    global models\n",
    "    for i in range(0,100):\n",
    "     #creating base model classifier\n",
    "        models.append(MultinomialNB()) #linear_model.Perceptron()\n",
    "        \n",
    "def fit(data,classdata):\n",
    "    global models\n",
    "   # global kArr\n",
    "    global train_class\n",
    "    for i in range(0, 100):\n",
    "        k = np.random.poisson(1,1)[0] #applying poisson distribution for the number of times training data stored\n",
    "        if (k>999):\n",
    "            k = 999\n",
    "        kArr[k]+=1\n",
    "        #fitting training and test data to the model\n",
    "        for j in range(0,k):\n",
    "            models[i].partial_fit(data, classdata, classes =[\"vgood\",\"good\",\"acc\",\"unacc\"])\n",
    "\n",
    "\n",
    "def predict(test_data):\n",
    "    prediction = []\n",
    "    for i in range(0, 100):\n",
    "        prediction.append(models[i].predict(test_data))\n",
    "    prediction = np.array(prediction).transpose()\n",
    "    Final = []\n",
    "    for each in prediction:\n",
    "        Final.append(Counter(each).most_common(1)[0][0])\n",
    "    #calculating general statistics by calling function\n",
    "    print (\"Precision is \", precision(test_class, np.array(Final)))\n",
    "    print (\"Recall is \", recall(test_class, np.array(Final)))\n",
    "    print (\"F1 score is \", f1score(test_class, np.array(Final)))\n",
    "    print (\"Accuracy is \", accuracy(test_class, np.array(Final)))\n",
    "    \n",
    "def main():\n",
    "    global models\n",
    "    global  kArr\n",
    "    models = []\n",
    "    kArr = [0]*1000\n",
    "    #while running please change the path of the file \n",
    "    LoadData1(\"F:/Semester 2/Machine Learning/Assignment/car.txt.DATA\")\n",
    "    addModels()\n",
    "    \n",
    "    start = 0\n",
    "    end = len(train_data)\n",
    "    offset = 20 #processing 20 chunks of data at a time\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    while(start < end):\n",
    "        if (count%20 == 0):\n",
    "            print (count)\n",
    "        count += 1\n",
    "        \n",
    "        data = train_data[start:start + offset]\n",
    "        classdata = train_class[start:start + offset]\n",
    "        start += offset\n",
    "        fit(data,classdata)\n",
    "    predict(test_data)\n",
    "    print(\"time taken for online bagging\", time.time()-start_time)\n",
    "\n",
    "if __name__ == \"__main__\":main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing batch algorithms for car dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data \n",
    "#while running please change the path of the file \n",
    "car_data = pd.read_csv(\"F:/Semester 2/Machine Learning/Assignment/car.csv\",header = None,names = ['buying','maint','doors','persons','lug_boot','safety','class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      "buying      1728 non-null object\n",
      "maint       1728 non-null object\n",
      "doors       1728 non-null object\n",
      "persons     1728 non-null object\n",
      "lug_boot    1728 non-null object\n",
      "safety      1728 non-null object\n",
      "class       1728 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "car_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vhigh' 'high' 'med' 'low'] \t 4\n",
      "['vhigh' 'high' 'med' 'low'] \t 4\n",
      "['2' '3' '4' '5more'] \t 4\n",
      "['2' '4' 'more'] \t 3\n",
      "['small' 'med' 'big'] \t 3\n",
      "['low' 'med' 'high'] \t 3\n",
      "['unacc' 'acc' 'vgood' 'good'] \t 4\n"
     ]
    }
   ],
   "source": [
    "#as all the columns are categorical, checking for unique values of each column\n",
    "for i in car_data.columns:\n",
    "    print(car_data[i].unique(),\"\\t\",car_data[i].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vhigh    432\n",
      "high     432\n",
      "low      432\n",
      "med      432\n",
      "Name: buying, dtype: int64\n",
      "\n",
      "vhigh    432\n",
      "high     432\n",
      "low      432\n",
      "med      432\n",
      "Name: maint, dtype: int64\n",
      "\n",
      "2        432\n",
      "3        432\n",
      "5more    432\n",
      "4        432\n",
      "Name: doors, dtype: int64\n",
      "\n",
      "2       576\n",
      "more    576\n",
      "4       576\n",
      "Name: persons, dtype: int64\n",
      "\n",
      "big      576\n",
      "small    576\n",
      "med      576\n",
      "Name: lug_boot, dtype: int64\n",
      "\n",
      "high    576\n",
      "low     576\n",
      "med     576\n",
      "Name: safety, dtype: int64\n",
      "\n",
      "unacc    1210\n",
      "acc       384\n",
      "good       69\n",
      "vgood      65\n",
      "Name: class, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking how these unique categories are distributed among the columns\n",
    "for i in car_data.columns:\n",
    "    print(car_data[i].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x27a485d1b38>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(car_data['class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As scikit-learn algorithms do not generally work with string values, I've converted string categories to integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping classifiers to their intinsity\n",
    "car_data['buying'] = car_data['buying'].map({'vhigh' : 3,'high' : 2, 'med' : 1, 'low' : 0})\n",
    "car_data['maint'] = car_data['maint'].map({'vhigh' : 3,'high' : 2, 'med' : 1, 'low' : 0})\n",
    "car_data['doors'] = car_data['doors'].map({'5more' : 5, '2' : 2,'3' : 3, '4' : 4})\n",
    "car_data['persons'] = car_data['persons'].map({'more' : 5, '2' : 2, '4' : 4})\n",
    "car_data['lug_boot'] = car_data['lug_boot'].map({'small' : 0,'med' : 1, 'big' : 2})\n",
    "car_data['safety'] = car_data['safety'].map({'low' : 0,'med' : 1, 'high' : 2})\n",
    "car_data['class'] = car_data['class'].map({'unacc' : 0,'acc' : 1,'good' : 2,'vgood' : 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying  maint  doors  persons  lug_boot  safety  class\n",
       "1598       0      1      5        2         1       2      0\n",
       "1603       0      1      5        4         0       1      1\n",
       "459        2      3      3        2         0       0      0\n",
       "616        2      2      4        5         1       1      1\n",
       "1693       0      0      4        5         0       1      1\n",
       "1587       0      1      4        5         1       0      0\n",
       "53         3      3      3        5         2       2      0\n",
       "602        2      2      4        2         2       2      0\n",
       "1246       1      0      4        2         1       1      0\n",
       "280        3      1      4        4         0       1      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting 70% data to trainig and rest for testing\n",
    "train =car_data.sample(frac = 0.7)\n",
    "test = car_data.loc[car_data.index.isin(train.index)]\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is the dataframe containing input data / features y is the series which has results which are to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      buying  maint  doors  persons  lug_boot  safety\n",
       "1598       0      1      5        2         1       2\n",
       "1603       0      1      5        4         0       1\n",
       "459        2      3      3        2         0       0\n",
       "616        2      2      4        5         1       1\n",
       "1693       0      0      4        5         0       1\n",
       "1587       0      1      4        5         1       0\n",
       "53         3      3      3        5         2       2\n",
       "602        2      2      4        2         2       2\n",
       "1246       1      0      4        2         1       1\n",
       "280        3      1      4        4         0       1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Training\n",
    "x_train = train[train.columns[0:6]]\n",
    "y_train  = train[train.columns[6]]\n",
    "x_test = test[test.columns[0:6]]\n",
    "y_test = test[test.columns[6]]\n",
    "x_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9793236093992155\n",
      "F1 score is 0.9768236093992154\n",
      "Time taken for decision tree 0.18439722061157227\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "start_time = time.time()\n",
    "classifiers = {}\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.set_params(max_leaf_nodes = 50,max_depth = 10, max_features = None)\n",
    "dt_clf = clf.fit(x_train,y_train)\n",
    "dt_predict = dt_clf.predict(x_test)\n",
    "dt_acc = accuracy_score(y_test,dt_predict)\n",
    "param =  dt_clf.get_params()\n",
    "accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "print (\"Accuracy is\",  accuracy.mean())#,f_score.mean())#, \"-\", recall.mean(), \"-\", precision_score.mean())\n",
    "print (\"F1 score is\",  f_score.mean())\n",
    "classifiers[\"DT\"]=clf \n",
    "t0 =  time.time()-start_time\n",
    "print(\"Time taken for decision tree\",t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9859955023589071\n",
      "F1 score is 0.9859955023589071\n",
      "Time taken for SVM 0.9864838123321533\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machines\n",
    "start_time = time.time()\n",
    "clf = svm.SVC(gamma = 'auto')\n",
    "clf.set_params(C = 100, kernel = \"rbf\")\n",
    "svm_clf = clf.fit(x_train,y_train)\n",
    "svm_predict = svm_clf.predict(x_test)\n",
    "svm_acc = accuracy_score(y_test,svm_predict)\n",
    "accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "print (\"Accuracy is\",  accuracy.mean())\n",
    "print (\"F1 score is\",  f_score.mean())\n",
    "classifiers[\"SVM\"]=clf\n",
    "t1 =  time.time()-start_time\n",
    "print(\"Time taken for SVM\",t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9851492790424932\n",
      "F1 score is 0.9834619566374109\n",
      "Time taken for Bagging 1.8474836349487305\n"
     ]
    }
   ],
   "source": [
    "#Bagging\n",
    "start_time = time.time()\n",
    "clf = BaggingClassifier()\n",
    "clf.set_params(n_estimators = 30,max_samples = 1000)\n",
    "bg_clf = clf.fit(x_train,y_train)\n",
    "bg_predict = bg_clf.predict(x_test)\n",
    "bg_acc = accuracy_score(y_test,bg_predict)\n",
    "accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "print (\"Accuracy is\",  accuracy.mean())\n",
    "print (\"F1 score is\",  f_score.mean())\n",
    "classifiers[\"BG\"]=clf\n",
    "t2 =  time.time()-start_time\n",
    "print(\"Time taken for Bagging\",t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9751561715134439\n",
      "F1 score is 0.9768028380934128\n",
      "Time taken for Random forest 4.833299398422241\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "start_time = time.time()\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10)\n",
    "rf_clf = clf.fit(x_train,y_train)\n",
    "rf_predict = rf_clf.predict(x_test)\n",
    "rf_acc = accuracy_score(y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "print (\"Accuracy is\",  accuracy.mean())\n",
    "print (\"F1 score is\",  f_score.mean())\n",
    "classifiers[\"RF\"]=clf\n",
    "t3 =  time.time()-start_time\n",
    "print(\"Time taken for Random forest\",t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.8554744530695675\n",
      "F1 score is 0.8554744530695675\n",
      "Time taken for Adaboost 0.8078839778900146\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "start_time = time.time()\n",
    "clf = AdaBoostClassifier()\n",
    "clf.set_params(n_estimators = 10, learning_rate = 1)\n",
    "ada_clf = clf.fit(x_train,y_train)\n",
    "ada_predict = ada_clf.predict(x_test)\n",
    "ada_acc = accuracy_score(y_test,ada_predict)\n",
    "accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "print (\"Accuracy is\",  accuracy.mean())\n",
    "print (\"F1 score is\",  f_score.mean())\n",
    "classifiers[\"ADA\"]=clf\n",
    "t4 =  time.time()-start_time\n",
    "print(\"Time taken for Adaboost\",t4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7643918139666732\n",
      "F1 score is 0.7643918139666732\n",
      "Time taken for Perceptron 0.30675649642944336\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "start_time = time.time()\n",
    "clf = linear_model.Perceptron()\n",
    "clf.set_params(alpha = 0.0001)\n",
    "pt_clf = clf.fit(x_train,y_train)\n",
    "pt_predict = pt_clf.predict(x_test)\n",
    "pt_acc = accuracy_score(y_test,pt_predict)\n",
    "accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "print (\"Accuracy is\",  accuracy.mean())\n",
    "print (\"F1 score is\",  f_score.mean())\n",
    "classifiers[\"PT\"]=clf\n",
    "t5 =  time.time()-start_time\n",
    "print(\"Time taken for Perceptron\",t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7108394982893718\n",
      "F1 score is 0.7108394982893718\n",
      "Time taken for Naive bayes 0.15760064125061035\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "start_time = time.time()\n",
    "clf = MultinomialNB()\n",
    "clf.set_params(alpha = 0.1)\n",
    "nb_clf = clf.fit(x_train,y_train)\n",
    "nb_predict = nb_clf.predict(x_test)\n",
    "nb_acc = accuracy_score(y_test,nb_predict)\n",
    "accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "print (\"Accuracy is\",  accuracy.mean())\n",
    "print (\"F1 score is\",  f_score.mean())\n",
    "classifiers[\"NB\"]=clf\n",
    "t6 =  time.time()-start_time\n",
    "print(\"Time taken for Naive bayes\",t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy             F-score\n",
      "DT\n",
      "   0.9561983471074379    0.9537190082644628\n",
      "SVM\n",
      "   0.9818181818181818    0.9818181818181818\n",
      "BG\n",
      "   0.9727272727272729    0.9776859504132233\n",
      "RF\n",
      "   0.9719008264462812    0.9768595041322315\n",
      "ADA\n",
      "   0.8314049586776859    0.8314049586776859\n",
      "PT\n",
      "   0.7644628099173554    0.7644628099173555\n",
      "NB\n",
      "   0.7057851239669422    0.7057851239669423\n"
     ]
    }
   ],
   "source": [
    "print (\"   accuracy\",\"           \",\"F-score\",)\n",
    "for clf in classifiers.values():\n",
    "    accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "    f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "    n = len(t)\n",
    "    for i in classifiers:\n",
    "        if classifiers[i]== clf:\n",
    "            print (i),\n",
    "            break\n",
    "    print ( \"  \",accuracy.mean(), \"  \",f_score.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.18439722061157227)\n",
      "(1, 0.9864838123321533)\n",
      "(2, 1.8474836349487305)\n",
      "(3, 4.833299398422241)\n",
      "(4, 0.8078839778900146)\n",
      "(5, 0.30675649642944336)\n",
      "(6, 0.15760064125061035)\n"
     ]
    }
   ],
   "source": [
    "t = [t0,t1,t2,t3,t4,t5,t6]\n",
    "b = enumerate(t)\n",
    "for i in b:\n",
    "    print(i)\n",
    "    #0 - Decision tree\n",
    "    #1 - SVM\n",
    "    #2 - Bagging\n",
    "    #3 - Random forest\n",
    "    #4 - AdaBoost\n",
    "    #5 - Perceptron\n",
    "    #6 - Naive Bayes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
