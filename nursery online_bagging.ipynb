{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import csv\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import random\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data \n",
    "#while running please change the path of the file \n",
    "nursery_data = pd.read_csv(\"F:/Semester 2/Machine Learning/Assignment/nursery.data\",header = None,names = [\"parents\",\"has_nurs\",\"form\",\"children\",\"housing\",\"finance\",\"social\",\"health\",\"class\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usual' 'pretentious' 'great_pret'] \t 3\n",
      "['proper' 'less_proper' 'improper' 'critical' 'very_crit'] \t 5\n",
      "['complete' 'completed' 'incomplete' 'foster'] \t 4\n",
      "['1' '2' '3' 'more'] \t 4\n",
      "['convenient' 'less_conv' 'critical'] \t 3\n",
      "['convenient' 'inconv'] \t 2\n",
      "['nonprob' 'slightly_prob' 'problematic'] \t 3\n",
      "['recommended' 'priority' 'not_recom'] \t 3\n",
      "['recommend' 'priority' 'not_recom' 'very_recom' 'spec_prior'] \t 5\n"
     ]
    }
   ],
   "source": [
    "#as all the columns are categorical, checking for unique values of each column\n",
    "for i in nursery_data.columns:\n",
    "    print(nursery_data[i].unique(),\"\\t\",nursery_data[i].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Bagging for nursery dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "Precision is  0.8354081492029951\n",
      "Recall is  0.8354081492029951\n",
      "F1 score is  0.8354081492029951\n",
      "Accuracy is  0.8354081492029951\n",
      "68.85277605056763\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global train_data\n",
    "global train_class\n",
    "global test_data\n",
    "global test_class\n",
    "global models\n",
    "global kArr\n",
    "\n",
    "def f1score(y_true,y_pred):\n",
    "    f1=f1_score(y_true, y_pred, average= 'micro')\n",
    "    return f1\n",
    "def precision(y_true,y_pred):\n",
    "    pre=precision_score(y_true, y_pred, average='micro')\n",
    "    return pre\n",
    "def recall(y_true,y_pred):\n",
    "    recall=recall_score(y_true, y_pred, average='micro')\n",
    "    return recall\n",
    "def accuracy(y_true,y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def LoadData1(path):\n",
    "    global train_data\n",
    "    global train_class\n",
    "    global test_data\n",
    "    global test_class\n",
    "    data = []\n",
    "    with open(path) as csvfile:\n",
    "        data1 = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        for each in data1:\n",
    "            X = []\n",
    "            for x in each:\n",
    "                #print x\n",
    "                if (x == \"very_crit\"):\n",
    "                    x=4\n",
    "                elif (x==\"proper\" or x == \"incomplete\" or x == \"more\"):\n",
    "                    x=3\n",
    "                elif (x == \"usual\" or x == \"less_proper\" or x == \"foster\" or x == \"3\" or x == \"less_conv\" or x == \"slightly_prob\" or x == \"recommended\"):\n",
    "                    x=2\n",
    "                elif (x == \"pretentious\" or x == \"improper\" or x == \"completed\" or x == \"2\" or x == \"critical\" or x == \"inconv\" or x == \"problematic\" or x == \"priority\"):\n",
    "                    x=1\n",
    "                elif (x == \"great_pret\" or x == \"critical\" or x == \"complete\" or x == \"1\" or x == \"convenient\" or x == \"convenient\" or x == \"not_recom\" or x == \"nonprob\"):\n",
    "                    x=0  \n",
    "                    \n",
    "                X.append(x)\n",
    "                Y = X\n",
    "                \n",
    "            if (Y[-1] == \"very_recom\"):\n",
    "                for i in range(10):\n",
    "                    data.append(Y)\n",
    "            elif (Y[-1] == \"spec_prior\"):\n",
    "                for i in range(15):\n",
    "                    data.append(Y)\n",
    "            elif (Y[-1] == \"recommend\"):\n",
    "                for i in range(17):\n",
    "                    data.append(Y)\n",
    "            elif (Y[-1] == \"priority\"):\n",
    "                for i in range(18):\n",
    "                    data.append(Y)\n",
    "            else:\n",
    "                data.append(Y)\n",
    "                   \n",
    "    shuffle(data)\n",
    "    size = int(len(data) * 0.7)\n",
    "    train_data = data[0:size]\n",
    "    test_data = data[size:len(data)]\n",
    "    train_class = np.array(train_data)[:, len(train_data[0]) - 1]\n",
    "    train_data = np.array(train_data)[:, range(0, len(train_data[0]) - 1)]\n",
    "    test_class = np.array(test_data)[:, len(test_data[0]) - 1]\n",
    "    test_data = np.array(test_data)[:, range(0, len(test_data[0]) - 1)]\n",
    "    train_data = [[int(j) for j in i] for i in train_data]\n",
    "    test_data = [[int(j) for j in i] for i in test_data]\n",
    "    \n",
    "def addModels():\n",
    "    global models\n",
    "    for i in range(0,1000):\n",
    "        models.append(MultinomialNB())\n",
    "        \n",
    "def fit(data,classdata):\n",
    "    global models\n",
    "    global kArr\n",
    "    global train_class\n",
    "    for i in range(0, 100):\n",
    "        k = np.random.poisson(1,1)[0]\n",
    "        if (k>999):\n",
    "            k = 999\n",
    "        kArr[k]+=1\n",
    "        for j in range(0,k):\n",
    "            models[i].partial_fit(data, classdata, classes =[\"recommend\", \"priority\", \"not_recom\", \"very_recom\", \"spec_prior\"])\n",
    "\n",
    "\n",
    "def predict(test_data):\n",
    "    prediction = []\n",
    "    for i in range(0, 100):\n",
    "        prediction.append(models[i].predict(test_data))\n",
    "    prediction = np.array(prediction).transpose()\n",
    "    Final = []\n",
    "    for each in prediction:\n",
    "        Final.append(Counter(each).most_common(1)[0][0])\n",
    "    #print (test_class, Final)\n",
    "    print (\"Precision is \", precision(test_class, np.array(Final)))\n",
    "    print (\"Recall is \", recall(test_class, np.array(Final)))\n",
    "    print (\"F1 score is \", f1score(test_class, np.array(Final)))\n",
    "    print (\"Accuracy is \", accuracy(test_class, np.array(Final)))\n",
    "    \n",
    "def main():\n",
    "    global models\n",
    "    global  kArr\n",
    "    models = []\n",
    "    kArr = [0]*100\n",
    "    #while running please change the path of the file \n",
    "    LoadData1(\"F:/Semester 2/Machine Learning/Assignment/nursery.DATA\")\n",
    "    addModels()\n",
    "    \n",
    "    start = 0\n",
    "    end = len(train_data)\n",
    "    offset = 100\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    while(start < end):\n",
    "        if (count%100 == 0):\n",
    "            print (count)\n",
    "        count += 1\n",
    "        \n",
    "        data = train_data[start:start + offset]\n",
    "        classdata = train_class[start:start + offset]\n",
    "        start += offset\n",
    "        fit(data,classdata)\n",
    "    predict(test_data)\n",
    "    print(time.time()-start_time)\n",
    "    #print('kArr',kArr)\n",
    "\n",
    "if __name__ == \"__main__\":main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing batch algorithms for nursery dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>problematic</td>\n",
       "      <td>recommended</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>problematic</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>problematic</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>inconv</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>very_recom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parents has_nurs      form children     housing     finance         social  \\\n",
       "0   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "1   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "2   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "3   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "4   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "5   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "6   usual   proper  complete        1  convenient  convenient    problematic   \n",
       "7   usual   proper  complete        1  convenient  convenient    problematic   \n",
       "8   usual   proper  complete        1  convenient  convenient    problematic   \n",
       "9   usual   proper  complete        1  convenient      inconv        nonprob   \n",
       "\n",
       "        health       class  \n",
       "0  recommended   recommend  \n",
       "1     priority    priority  \n",
       "2    not_recom   not_recom  \n",
       "3  recommended   recommend  \n",
       "4     priority    priority  \n",
       "5    not_recom   not_recom  \n",
       "6  recommended    priority  \n",
       "7     priority    priority  \n",
       "8    not_recom   not_recom  \n",
       "9  recommended  very_recom  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#while running please change the path of the file \n",
    "nursery_data = pd.read_csv(\"F:/Semester 2/Machine Learning/Assignment/nursery.data\", names=[\"parents\",\"has_nurs\",\"form\",\"children\",\"housing\",\"finance\",\"social\",\"health\",\"class\"])\n",
    "nursery_data.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12960 entries, 0 to 12959\n",
      "Data columns (total 9 columns):\n",
      "parents     12960 non-null object\n",
      "has_nurs    12960 non-null object\n",
      "form        12960 non-null object\n",
      "children    12960 non-null object\n",
      "housing     12960 non-null object\n",
      "finance     12960 non-null object\n",
      "social      12960 non-null object\n",
      "health      12960 non-null object\n",
      "class       12960 non-null object\n",
      "dtypes: object(9)\n",
      "memory usage: 911.3+ KB\n"
     ]
    }
   ],
   "source": [
    "nursery_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usual' 'pretentious' 'great_pret'] \t 3\n",
      "['proper' 'less_proper' 'improper' 'critical' 'very_crit'] \t 5\n",
      "['complete' 'completed' 'incomplete' 'foster'] \t 4\n",
      "['1' '2' '3' 'more'] \t 4\n",
      "['convenient' 'less_conv' 'critical'] \t 3\n",
      "['convenient' 'inconv'] \t 2\n",
      "['nonprob' 'slightly_prob' 'problematic'] \t 3\n",
      "['recommended' 'priority' 'not_recom'] \t 3\n",
      "['recommend' 'priority' 'not_recom' 'very_recom' 'spec_prior'] \t 5\n"
     ]
    }
   ],
   "source": [
    "#as all the columns are categorical, checking for unique values of each column\n",
    "for i in nursery_data.columns:\n",
    "    print(nursery_data[i].unique(),\"\\t\",nursery_data[i].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x204ca45e160>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(nursery_data['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph shows how many instances of data have been spreaded into different categories. Though the dataset may be biased towards priority, not recommended and specific priority, we can proceed with this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12960, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Categorical\n",
    "features = [\"children\",\"housing\",\"class\",\"has_nurs\",\"social\",\"finance\"]\n",
    "for column in features:\n",
    "    nursery_data[column] = nursery_data[column].astype(\"category\").cat.codes\n",
    "\n",
    "\n",
    "features1 = ['parents','form','health']\n",
    "x1 = nursery_data.drop(features1, axis = 1)\n",
    "\n",
    "# Geting Dummies as target is categorical and has more than 2 values.\n",
    "x2 = nursery_data.drop(features, axis = 1)\n",
    "x2 = pd.get_dummies(x2)\n",
    "\n",
    "#Concatinating into a dataframe\n",
    "x = pd.concat([x1, x2], axis = 1)\n",
    "\n",
    "#separating target attribute from the rest of the data\n",
    "target = [\"class\"]\n",
    "X = x.drop(target, axis = 1)\n",
    "target = x[target]\n",
    "Y = pd.DataFrame(target)\n",
    "Y = np.array(Y)\n",
    "Y = np.ravel(Y) #converting array to vector\n",
    "\n",
    "X.shape    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12960, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying principal component analysis, to reduce number of attributes\n",
    "pca = PCA(n_components=8)\n",
    "xtr = pca.fit_transform(X)\n",
    "\n",
    "xtr.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(xtr,Y, test_size=0.3)\n",
    "\n",
    "#scaling train and test dataset\n",
    "x_train.reshape(-1, 1) #reshapinng the data\n",
    "y_train.reshape(-1, 1)\n",
    "x_train = MinMaxScaler().fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is the dataframe containing input data / features y is the series which has results which are to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.8820469518119298\n",
      "F1 score is 0.8820469518119296\n",
      "Time taken for decision tree 0.35764026641845703\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "start_time = time.time()\n",
    "classifiers = {}\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.set_params(max_leaf_nodes = 1000,max_depth = 5)\n",
    "dt_clf = clf.fit(x_train,y_train)\n",
    "dt_predict = dt_clf.predict(x_test)\n",
    "dt_acc = accuracy_score(y_test,dt_predict)\n",
    "param =  dt_clf.get_params()\n",
    "accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "print (\"Accuracy is\",  accuracy.mean())#,f_score.mean())#, \"-\", recall.mean(), \"-\", precision_score.mean())\n",
    "print (\"F1 score is\",  f_score.mean())\n",
    "classifiers[\"DT\"]=clf \n",
    "t0 =  time.time()-start_time\n",
    "print(\"Time taken for decision tree\",t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9377231115607275\n",
      "F1 score is 0.9377231115607275\n",
      "Time taken for SVM 87.48754644393921\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machines\n",
    "start_time = time.time()\n",
    "clf = svm.SVC(gamma = 'auto')\n",
    "clf.set_params(C = 1000, kernel = \"rbf\")\n",
    "svm_clf = clf.fit(x_train,y_train)\n",
    "svm_predict = svm_clf.predict(x_test)\n",
    "svm_acc = accuracy_score(y_test,svm_predict)\n",
    "accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "print (\"Accuracy is\",  accuracy.mean())\n",
    "print (\"F1 score is\",  f_score.mean())\n",
    "classifiers[\"SVM\"]=clf\n",
    "t1 =  time.time()-start_time\n",
    "print(\"Time taken for SVM\",t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9303341958835329\n",
      "F1 score is 0.9291233482007168\n",
      "Time taken for Bagging 3.7329041957855225\n"
     ]
    }
   ],
   "source": [
    "#Bagging\n",
    "start_time = time.time()\n",
    "clf = BaggingClassifier()\n",
    "clf.set_params(n_estimators = 30,max_samples = 1000)\n",
    "bg_clf = clf.fit(x_train,y_train)\n",
    "bg_predict = bg_clf.predict(x_test)\n",
    "bg_acc = accuracy_score(y_test,bg_predict)\n",
    "accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "print (\"Accuracy is\",  accuracy.mean())\n",
    "print (\"F1 score is\",  f_score.mean())\n",
    "classifiers[\"BG\"]=clf\n",
    "t2 =  time.time()-start_time\n",
    "print(\"Time taken for Bagging\",t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.9237234658596281\n",
      "F1 score is 0.9235032004737995\n",
      "Time taken for Random forest 15.050720691680908\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "start_time = time.time()\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10)\n",
    "rf_clf = clf.fit(x_train,y_train)\n",
    "rf_predict = rf_clf.predict(x_test)\n",
    "rf_acc = accuracy_score(y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "print (\"Accuracy is\",  accuracy.mean())\n",
    "print (\"F1 score is\",  f_score.mean())\n",
    "classifiers[\"RF\"]=clf\n",
    "t3 =  time.time()-start_time\n",
    "print(\"Time taken for Random forest\",t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7445007265795097\n",
      "F1 score is 0.7445007265795096\n",
      "Time taken for Adaboost 14.837157011032104\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "start_time = time.time()\n",
    "clf = AdaBoostClassifier()\n",
    "clf.set_params(n_estimators = 100, learning_rate = 1)\n",
    "ada_clf = clf.fit(x_train,y_train)\n",
    "ada_predict = ada_clf.predict(x_test)\n",
    "ada_acc = accuracy_score(y_test,ada_predict)\n",
    "accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "print (\"Accuracy is\",  accuracy.mean())\n",
    "print (\"F1 score is\",  f_score.mean())\n",
    "classifiers[\"ADA\"]=clf\n",
    "t4 =  time.time()-start_time\n",
    "print(\"Time taken for Adaboost\",t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7237472235312263\n",
      "F1 score is 0.7237472235312263\n",
      "Time taken for Perceptron 1.3353571891784668\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "start_time = time.time()\n",
    "clf = linear_model.Perceptron()\n",
    "clf.set_params(alpha = 0.0001)\n",
    "pt_clf = clf.fit(x_train,y_train)\n",
    "pt_predict = pt_clf.predict(x_test)\n",
    "pt_acc = accuracy_score(y_test,pt_predict)\n",
    "accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "print (\"Accuracy is\",  accuracy.mean())\n",
    "print (\"F1 score is\",  f_score.mean())\n",
    "classifiers[\"PT\"]=clf\n",
    "t5 =  time.time()-start_time\n",
    "print(\"Time taken for Perceptron\",t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7679603221011193\n",
      "F1 score is 0.7679603221011193\n",
      "Time taken for Naive bayes 0.17846274375915527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\tools\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "start_time = time.time()\n",
    "x_train.reshape(-1, 1)\n",
    "y_train.reshape(-1, 1)\n",
    "clf = MultinomialNB()\n",
    "clf.set_params(alpha = 0.1)\n",
    "nb_clf = clf.fit(x_train,y_train)\n",
    "nb_predict = nb_clf.predict(x_test)\n",
    "nb_acc = accuracy_score(y_test,nb_predict)\n",
    "accuracy = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, x_train , y_train, cv=10,scoring = 'f1_micro')\n",
    "print (\"Accuracy is\",  accuracy.mean())\n",
    "print (\"F1 score is\",  f_score.mean())\n",
    "classifiers[\"NB\"]=clf\n",
    "t6 =  time.time()-start_time\n",
    "print(\"Time taken for Naive bayes\",t6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.35764026641845703)\n",
      "(1, 87.48754644393921)\n",
      "(2, 3.7329041957855225)\n",
      "(3, 15.050720691680908)\n",
      "(4, 14.837157011032104)\n",
      "(5, 1.3353571891784668)\n",
      "(6, 0.17846274375915527)\n"
     ]
    }
   ],
   "source": [
    "t = [t0,t1,t2,t3,t4,t5,t6]\n",
    "b = enumerate(t)\n",
    "for i in b:\n",
    "    print(i) #shows time taken for classifiers in seconds \n",
    "    #0 - Decision tree\n",
    "    #1 - SVM\n",
    "    #2 - Bagging\n",
    "    #3 - Random forest\n",
    "    #4 - AdaBoost\n",
    "    #5 - Perceptron\n",
    "    #6 - Naive Bayes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
